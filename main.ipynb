{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efbf523-c6b1-4440-9299-15c09173fbea",
   "metadata": {},
   "source": [
    "# Quantum Computing -based Optimization for Sustainable Data Workflows in Cloud Infrastructures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6037-7843-4083-8215-675d97aa952b",
   "metadata": {},
   "source": [
    "by [Valter Uotila](https://researchportal.helsinki.fi/en/persons/valter-johan-edvard-uotila), PhD student, [Unified Database Management Systems](https://www2.helsinki.fi/en/researchgroups/unified-database-management-systems-udbms/news), University of Helsinki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be83192-8331-4177-ab26-d4a37ad81e97",
   "metadata": {},
   "source": [
    "This is just a specified shortest path finding application applied to the problem presented in the [document](https://github.com/valterUo/Quantum-Computing-based-Optimization-for-Sustainable-Data-Workflows-in-Cloud/blob/main/Quantum_Computing__based_Optimization_for_Sustainable_Data_Workflows_in_Cloud.pdf) that comes along with this implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774c742-8f1d-4edf-af43-af3866b25424",
   "metadata": {},
   "source": [
    "Possible quantum software-harware combinations to solve the problem:\n",
    "\n",
    "1. Amazon Braket's D-Wave — Advantage and D-Wave — 2000Q\n",
    "    1. Ocean implementation of this code\n",
    "2. Amazon Braket's IonQ and Rigetti machines\n",
    "    1. Qiskit implementation of this code\n",
    "3. Amazon Braket's simulators\n",
    "    1. Qiskit implementation of this code\n",
    "4. D-wave's Leap Advantage\n",
    "    1. Ocean implementation of this code\n",
    "5. IBM Quantum systems\n",
    "    1. Qiskit implementation of this code\n",
    "6. Local machine\n",
    "    1. Both Ocean and Qiskit versions and also the non-quantum version of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7b9f0-1c98-423f-aa21-701a50d6f5c7",
   "metadata": {},
   "source": [
    "Because I am familiar with the Ocean framework and it is specially designed for formulating QUBOs, I initially formulated the problem using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ec7e3-bc29-4470-98bb-9e06c57ec2d1",
   "metadata": {},
   "source": [
    "## Chapter 1: Implementation using Ocean connecting to Amazon Braket quantum annealers or D-wave Leap quantum annealers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3c7485-15bb-4983-aef2-cbdd4d1aac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "from dimod.generators.constraints import combinations\n",
    "from dwave.system import LeapHybridSampler\n",
    "from hybrid.reference import KerberosSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "\n",
    "from braket.aws import AwsDevice\n",
    "from braket.ocean_plugin import BraketSampler, BraketDWaveSampler\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notebook_path = os.path.abspath(\"main.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c58b30-9cac-44ff-80e0-74b26e571349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_linear_safe(variable, value, linear_dict):\n",
    "    if variable in linear_dict.keys():\n",
    "        linear_dict[variable] = linear_dict[variable] + value\n",
    "    else:\n",
    "        linear_dict[variable] = value\n",
    "\n",
    "def append_quadratic_safe(variable, value, quadratic_dict):\n",
    "    if variable in quadratic_dict.keys():\n",
    "        quadratic_dict[variable] = quadratic_dict[variable] + value\n",
    "    else:\n",
    "        quadratic_dict[variable] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce68ea1-d49c-4060-9f94-739a02b61a6e",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ab1f70-b45b-4362-bc5f-68999bb694b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_partners_file_path = os.path.join(os.path.dirname(notebook_path), \"data/cloud_partners.json\")\n",
    "f = open(cloud_partners_file_path)\n",
    "partners_root = json.load(f)\n",
    "cloud_partners = partners_root[\"cloud_partners\"]\n",
    "\n",
    "workload_name = \"workload1.json\"\n",
    "workload_file_path = os.path.join(os.path.dirname(notebook_path), \"data/workloads/\" + workload_name)\n",
    "f = open(workload_file_path)\n",
    "workload_root = json.load(f)\n",
    "workload = workload_root[\"workload\"]\n",
    "\n",
    "#print(cloud_partners)\n",
    "#print(workload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd5ccb-ab3c-494d-a95b-915f60d12bf5",
   "metadata": {},
   "source": [
    "## Emission simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d0aaf-aaf4-46f7-b37e-48bcbc3f2dc5",
   "metadata": {},
   "source": [
    "This section implements an emission simulator which simulates emission changes in data center operations. Note that it is relatively hard to get accurate data from individual data centers. This simulator is just for demonstration and it does not have an actual scientific background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bcb9bb-43b2-4cb1-a297-c23b6b8708e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_simulator(variable1, variable2, cloud_partners, workload):\n",
    "    simulated_carbon_footprint = 1\n",
    "    emission_factor = 1\n",
    "    workload_type_in_process = None\n",
    "    \n",
    "    source_data_center_id = variable1[1]\n",
    "    work_in_process = variable2[0]\n",
    "    target_data_center_id = variable2[1]\n",
    "    \n",
    "    for work in workload:\n",
    "        if work[\"work_id\"] == int(work_in_process):\n",
    "            emission_factor = work[\"emission_factor\"]\n",
    "            workload_type_in_process = work[\"work_type\"]\n",
    "    \n",
    "    for partner in cloud_partners:\n",
    "        for center in partner[\"data_centers\"]:\n",
    "            if target_data_center_id == center[\"center_id\"]:\n",
    "                for workload_type in center[\"workload_dependent_emissions\"]:\n",
    "                    if workload_type_in_process == workload_type[\"workload_type\"]:\n",
    "                        interval = workload_type[\"emission_interval\"]\n",
    "                        #print(interval)\n",
    "                        simulated_carbon_footprint = emission_factor*random.uniform(interval[0], interval[1])\n",
    "            \n",
    "    return simulated_carbon_footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa518671-f5cc-43b3-8cbd-363d8a30f06e",
   "metadata": {},
   "source": [
    "## Creating variables for the binary quadratic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74690d-32f8-4e23-bea3-4710042fcf4b",
   "metadata": {},
   "source": [
    "We defined variables to be $ x_{i,j} = (w_i, d_j) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd702685-2279-4e62-9ce2-3af9de8b92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that any work can be executed on any data center\n",
    "def construct_variables(start_id):\n",
    "    variables = dict()\n",
    "    workload_order = []\n",
    "    for work in workload[start_id:]:\n",
    "        variables[str(work[\"work_id\"])] = list()\n",
    "        workload_order.append(str(work[\"work_id\"]))\n",
    "        for partner in cloud_partners:\n",
    "            for center in partner[\"data_centers\"]:\n",
    "                # The each key in the variables dictionary corresponds to a level in a tree i.e. a time step in the workflow\n",
    "                variables[str(work[\"work_id\"])].append((str(work[\"work_id\"]), center[\"center_id\"]))\n",
    "    return variables, workload_order\n",
    "            \n",
    "#print(json.dumps(variables, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6199eb-3f5e-4e91-a882-ff80136fcbcb",
   "metadata": {},
   "source": [
    "## Constructing constraints "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0502bff-f291-45b0-a710-a0c5b153fef7",
   "metadata": {},
   "source": [
    "### Constraint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7801573-9127-4f54-ad3b-28aca620ac5a",
   "metadata": {},
   "source": [
    "This constraint implements the requirement that for every work $ w_i $ we have exactly one variable $ x_{i,j} = (w_i, d_j) = 1$. In other words, this means that every work is executed on a single data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7bc9f9-b944-4fbe-8069-2ccc3680b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bqm_constraint1(bqm, variables):\n",
    "    strength = 25.0\n",
    "    for work_id in variables:\n",
    "        one_work_bqm = combinations(variables[work_id], 1, strength=strength)\n",
    "        bqm.update(one_work_bqm)\n",
    "    return bqm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbdb8a-44b2-4c36-aa22-b44f490355b4",
   "metadata": {},
   "source": [
    "### Constraint 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c4051-e147-4517-8176-0bc3efaab475",
   "metadata": {},
   "source": [
    "This constraint implements the requirement that for every pair of variables $x_{i,j} = (w_i, d_j)$ and $x_{i+1,k} = (w_{i+1}, d_k)$ we associate the (estimated emission) coefficient $e(x_{i,j}, x_{i+1,k})$. This coefficient is calculated in emission_simulator function. Note that we need to calculate this only for those pairs, where the works $w_i$ and $w_{i+1}$ are consecutive works in the workload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1731c43-df52-4056-aa1e-1cc817aeacce",
   "metadata": {},
   "source": [
    "To evaluate the algorithm we store the tree in a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405cb56c-74e8-4769-ad68-181fef27f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bqm_constraint2(bqm, variables, workload_order):\n",
    "    vartype = dimod.BINARY\n",
    "    A = 1\n",
    "    linear = dict()\n",
    "    quadratic = dict()\n",
    "    offset = 0.0\n",
    "    tree = nx.Graph()\n",
    "\n",
    "    for work_id_current in range(len(workload_order) - 1):\n",
    "        work_id_next = work_id_current + 1\n",
    "        key_current = workload_order[work_id_current]\n",
    "        key_next = workload_order[work_id_next]\n",
    "\n",
    "        for work1 in variables[key_current]:\n",
    "            for work2 in variables[key_next]:\n",
    "                coeff = emission_simulator(work1, work2, cloud_partners, workload)\n",
    "                append_quadratic_safe((work1, work2), coeff, quadratic)\n",
    "                tree.add_edge(work1, work2, weight=coeff)\n",
    "\n",
    "                #print(\"Works\", work1, work2)\n",
    "                #print(\"Coefficient\", coeff)\n",
    "\n",
    "    bqm_c2 = dimod.BinaryQuadraticModel(linear, quadratic, offset, vartype)\n",
    "    bqm_c2.scale(A)\n",
    "    bqm.update(bqm_c2)\n",
    "    return bqm, tree\n",
    "\n",
    "#print(bqm)\n",
    "#print(bqm.to_numpy_vectors())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da83177-51ac-4765-a36c-ab4a85a686e4",
   "metadata": {},
   "source": [
    "## Demonstrating algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8816e245-2865-448d-8c3d-d6f3a53fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_optimal(solution, tree, optimal_weight):\n",
    "    current_total = 0\n",
    "    try:\n",
    "        for i in range(len(solution) - 1):\n",
    "            edge_weight = tree.get_edge_data(solution[i], solution[i+1])\n",
    "            current_total += edge_weight[\"weight\"]\n",
    "    except:\n",
    "      print(\"The quantum result contains edges which are not in the tree.\")\n",
    "    return np.abs(optimal_weight - current_total)/optimal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d00f96-829a-42d0-b462-8af9a1dc35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(sample, tree, optimal_weight = -1):\n",
    "    positive_solution = []\n",
    "    for varname, value in sample.items():\n",
    "        if value == 1:\n",
    "            positive_solution.append(varname)\n",
    "            print(varname, value)\n",
    "    if optimal_weight != -1:\n",
    "        print(\"Difference from the optimal \", compare_to_optimal(positive_solution, tree, optimal_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a08ab-3221-41ce-a365-23227f7e3fd6",
   "metadata": {},
   "source": [
    "### Wrapping up various methods to solve the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae0586e-e308-4b09-a492-7fde27d5ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_bqm_in_leap(bqm, sampler = \"Kerberos\"):\n",
    "    bqm.normalize()\n",
    "    if sampler == \"Kerberos\":\n",
    "        kerberos_sampler = KerberosSampler().sample(bqm, max_iter=10, convergence=3, qpu_params={'label': 'Data workflow optimization'})\n",
    "        sample = kerberos_sampler.first.sample\n",
    "    elif sampler == \"LeapHybrid\":\n",
    "        sampler = LeapHybridSampler()\n",
    "        sampleset = sampler.sample(bqm)\n",
    "        sample = sampleset.first.sample\n",
    "    return sample\n",
    "    \n",
    "    #print(sampleset)\n",
    "    #print(best_solution)\n",
    "    #sample = best_solution\n",
    "    #energy = sampleset.first.energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce703015-9869-4954-aa9c-4f334c7db668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_bqm_in_amazon_braket(bqm, system = \"Advantage\"):\n",
    "    device = None\n",
    "    num_reads = 1000\n",
    "    if system == \"Advantage\":\n",
    "        device = \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\"\n",
    "    elif system == \"2000Q\":\n",
    "        device = \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\"\n",
    "    sampler = BraketDWaveSampler(device_arn = device)\n",
    "    sampler = EmbeddingComposite(sampler)\n",
    "    sampleset = sampler.sample(bqm, num_reads=num_reads)\n",
    "    sample = sampleset.first.sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2053039f-9832-40c4-b107-f51a463e2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_simulated_annealing(bqm):\n",
    "    sampler = dimod.SimulatedAnnealingSampler()\n",
    "    sampleset = sampler.sample(bqm, num_reads=100)\n",
    "    sample = sampleset.first.sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b510e515-c45e-49f7-95bd-169dbe86f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_exactly(bqm):\n",
    "    sampler = dimod.ExactSolver()\n",
    "    sampleset = sampler.sample(bqm)\n",
    "    sample = sampleset.first.sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549a4ccf-b4b9-40ca-8cf3-6f92c54a2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_networkx(tree, variables, start_work):\n",
    "    possible_solutions = []\n",
    "    best_solution = None\n",
    "    min_weight = float('Inf')\n",
    "    for source_var in variables[start_work]:\n",
    "        for target_var in variables['5']:\n",
    "            possible_solutions.append(nx.dijkstra_path(tree, source=source_var, target=target_var))\n",
    "    for sol in possible_solutions:\n",
    "        current_total = 0\n",
    "        for i in range(len(sol) - 1):\n",
    "            edge_weight = tree.get_edge_data(sol[i], sol[i+1])\n",
    "            current_total += edge_weight[\"weight\"]\n",
    "        #print(\"Shortest path \", sol)\n",
    "        #print(\"Current total \", current_total)\n",
    "        if min_weight > current_total:\n",
    "            min_weight = current_total\n",
    "            best_solution = sol\n",
    "    return best_solution, min_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d6270-d44a-4051-a11d-7d8955f19442",
   "metadata": {},
   "source": [
    "### Run single time step (for test and demonstration purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf6324b-d690-42b2-83f6-9e990737e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vartype = dimod.BINARY\n",
    "# bqm = dimod.BinaryQuadraticModel({}, {}, 0.0, vartype)\n",
    "# variables = construct_variables(0)\n",
    "# bqm = construct_bqm_constraint1(bqm)\n",
    "# bqm, tree = construct_bqm_constraint2(bqm)\n",
    "# print(bqm)\n",
    "\n",
    "#print(\"The problem is to find the minimum path from some of the nodes ('0', x) to some of the nodes ('5', y). The weight of the edges are defined by carbon footprint associated to the computation.\")\n",
    "#nx.draw(tree, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390173-f0d1-42be-9924-490ea7c3ac6d",
   "metadata": {},
   "source": [
    "#### Optimal and correct solution for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4d8776-a48e-4893-94f2-8791856c3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_solution, optimal_weight = solve_with_networkx(tree, '0')\n",
    "#print(best_solution, optimal_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21cf8d-c862-40f6-a16a-c3f56358347f",
   "metadata": {},
   "source": [
    "The following results we obtain with annealing. Ideally we would be close to the results we obtain from the function solve_with_networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a5e589-0518-46d1-95d1-68d515e98db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Solution with Amazon Braket\")\n",
    "#solution = solve_bqm_in_amazon_braket(bqm)\n",
    "#print_solution(solution, tree, optimal_weight)\n",
    "\n",
    "#print(\"Solution with D-wave Leap\")\n",
    "#solve_bqm_in_leap(bqm)\n",
    "\n",
    "#print(\"Solution with simulated annealing\")\n",
    "#solve_with_simulated_annealing(bqm)\n",
    "\n",
    "#print(\"Exact solution (takes time)\")\n",
    "#solve_exactly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e494ed9-3502-440e-80e1-9f73a5def5b6",
   "metadata": {},
   "source": [
    "### Run the whole algorithm using the update function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6190528-392a-4a0e-b4ff-4f1e633b66bf",
   "metadata": {},
   "source": [
    "To make the problem and solution less non-trivial, we include the time component in the algorithm. One time step means that we have executed a single work on some of the data centers. At each time step, we check the current situation how sustainable way the data centers are running. For example, weather conditions (wind and amount of water in rivers, etc.) affect the production of green energy, and the data center's machines' characteristics determine part of the emissions. In real-life cases, the other workloads affect the decision, and we might need to switch to another data center. This demonstration possibly modifies these conditions more than they vary in real-life but this demonstrates better the idea of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8dbe45-b8c5-4c42-a78e-fc614f93d6d9",
   "metadata": {},
   "source": [
    "Initially we proposed the following functions for the updates. At this point we learned an interesting lesson. After running the updates we noticed that it is not trivial to update QUBOs afterwards since the dependencies between variables and their coefficients form complicated structures. Thus the algorithm works best if the QUBO is always constructed from the beginning. Anyway, it would be interesting to study update methods deeper. For example, we could construct a small \"difference QUBO\" and merge this into the orginal QUBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e6f4f9-c9fe-4606-b73c-cccb38d9c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_entire_workflow(solve_classical_optimal = True):\n",
    "    optimal_solution_quantum = []\n",
    "    optimal_weights_quantum = []\n",
    "    optimal_solution_networkx = []\n",
    "    optimal_weights_networkx = []\n",
    "    error_statistics = []\n",
    "   \n",
    "    # For each work in workload, find the current optimum data center\n",
    "    # After finding the data center, update the model to match with changed emission situation\n",
    "    for work in workload[:-1]:\n",
    "        \n",
    "        # Initialize BQM\n",
    "        vartype = dimod.BINARY\n",
    "        bqm = dimod.BinaryQuadraticModel({}, {}, 0.0, vartype)\n",
    "        variables, work_order = construct_variables(int(work[\"work_id\"]))\n",
    "        bqm = construct_bqm_constraint1(bqm, variables)\n",
    "        bqm, tree = construct_bqm_constraint2(bqm, variables, work_order)\n",
    "        \n",
    "        # Solve the problem classically in order to evaluate the algorihtm\n",
    "        if solve_classical_optimal:\n",
    "            best_solution, optimal_weight = solve_with_networkx(tree, variables, str(work['work_id']))\n",
    "            optimal_weights_networkx.append(optimal_weight)\n",
    "            print(\"Best solution with networkx: \", best_solution[0])\n",
    "            optimal_solution_networkx.append(best_solution[0])\n",
    "        \n",
    "        # Solve the problem on Amazon Braket\n",
    "        solution_quantum = solve_bqm_in_amazon_braket(bqm)\n",
    "        print(\"Optimal solution found by Amazon Braket:\")\n",
    "        print_solution(solution_quantum, tree, optimal_weight = optimal_weights_networkx[-1])\n",
    "        \n",
    "        # Calculate how much the quantum solution differs from the optimal\n",
    "        positive_solution = []\n",
    "        for varname, value in solution_quantum.items():\n",
    "            if value == 1:\n",
    "                positive_solution.append(varname)\n",
    "        optimal_solution_quantum.append(positive_solution[0])\n",
    "        #print(\"Positive solution \", positive_solution)\n",
    "        \n",
    "        quantum_solution_weight = 0\n",
    "        for i in range(len(positive_solution) - 1):\n",
    "            edge_weight = tree.get_edge_data(positive_solution[i], positive_solution[i+1])\n",
    "            quantum_solution_weight += edge_weight[\"weight\"]\n",
    "        optimal_weights_quantum.append(quantum_solution_weight)\n",
    "    \n",
    "    return optimal_solution_quantum, optimal_weights_quantum, optimal_solution_networkx, optimal_weights_networkx, error_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55078b-cb04-41bb-86a7-a84e1d0e9aa3",
   "metadata": {},
   "source": [
    "Finally we run the whole algorithm for the imported workloads and cloud partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "670e61d4-6e0a-4c19-822b-02db07db667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution with networkx:  ('0', '20')\n",
      "Optimal solution found by Amazon Braket:\n",
      "('0', '20') 1\n",
      "('1', '20') 1\n",
      "('2', '00') 1\n",
      "('3', '40') 1\n",
      "('4', '20') 1\n",
      "('5', '30') 1\n",
      "Difference from the optimal  0.01494087005158169\n",
      "Best solution with networkx:  ('1', '30')\n",
      "Optimal solution found by Amazon Braket:\n",
      "('1', '20') 1\n",
      "('2', '30') 1\n",
      "('3', '10') 1\n",
      "('4', '00') 1\n",
      "('5', '30') 1\n",
      "Difference from the optimal  0.023285989589212047\n",
      "Best solution with networkx:  ('2', '00')\n",
      "Optimal solution found by Amazon Braket:\n",
      "('2', '00') 1\n",
      "('3', '20') 1\n",
      "('4', '10') 1\n",
      "('5', '20') 1\n",
      "Difference from the optimal  0.0\n",
      "Best solution with networkx:  ('3', '30')\n",
      "Optimal solution found by Amazon Braket:\n",
      "('3', '30') 1\n",
      "('4', '30') 1\n",
      "('5', '10') 1\n",
      "Difference from the optimal  0.0\n",
      "Best solution with networkx:  ('4', '10')\n",
      "Optimal solution found by Amazon Braket:\n",
      "('4', '10') 1\n",
      "('5', '10') 1\n",
      "Difference from the optimal  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('0', '20'), ('1', '20'), ('2', '00'), ('3', '30'), ('4', '10')],\n",
       " [33.07813309839711,\n",
       "  14.37314678003243,\n",
       "  13.691469817050889,\n",
       "  3.1061327991413332,\n",
       "  1.0047409568661196],\n",
       " [('0', '20'), ('1', '30'), ('2', '00'), ('3', '30'), ('4', '10')],\n",
       " [32.59119232898366,\n",
       "  14.046070137051702,\n",
       "  13.691469817050889,\n",
       "  3.1061327991413332,\n",
       "  1.0047409568661196],\n",
       " [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimize_entire_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e5533-9632-4d03-bb95-f8dc8ad12988",
   "metadata": {},
   "source": [
    "## Chapter 2: Transfering problem to Qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fe1b7-cb71-423b-9ed0-9d7b30e913d4",
   "metadata": {},
   "source": [
    "In this part of the code I rely on the [Qiskit Tutorials](https://qiskit.org/documentation/optimization/tutorials/index.html). I want to learn to understand the connection between Ocean implementation and Qiskit. The formulation in Qiskit enables solving the problem using Braket simulators and IBM Quantum systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab11ca8-4dc4-442a-8474-7d256b0caedf",
   "metadata": {},
   "source": [
    "### Importing Qiskit, Amazon Braket simulators and Amazon Braket Universal gate-model QPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0a9e31b-2c3d-405b-9d4f-7ff6e05f41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a1260-5b4a-4675-a356-dbc4cec1467c",
   "metadata": {},
   "source": [
    "We start by importing a smaller data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f5fe6-8f51-493e-88a7-3c87312d39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_partners_file_path = os.path.join(os.path.dirname(notebook_path), \"data/cloud_partners_small.json\")\n",
    "f = open(cloud_partners_file_path)\n",
    "partners_root = json.load(f)\n",
    "cloud_partners_small = partners_root[\"cloud_partners\"]\n",
    "\n",
    "workload_name = \"workload2.json\"\n",
    "workload_file_path = os.path.join(os.path.dirname(notebook_path), \"data/workloads/\" + workload_name)\n",
    "f = open(workload_file_path)\n",
    "workload_root = json.load(f)\n",
    "workload_small = workload_root[\"workload\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f20698-c184-4678-ba3e-e1f4364c6066",
   "metadata": {},
   "source": [
    "### Transforming QUBO in Ocean to QUBO in Qiskit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faeb26c7-1237-4128-b8cb-a598d0f9523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QuadraticProgram()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
