{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efbf523-c6b1-4440-9299-15c09173fbea",
   "metadata": {},
   "source": [
    "# Practical Quantum Computing Approach for Sustainable Workflow Optimization in Cloud Infrastructures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6037-7843-4083-8215-675d97aa952b",
   "metadata": {},
   "source": [
    "by [Valter Uotila](https://researchportal.helsinki.fi/en/persons/valter-johan-edvard-uotila), PhD student, [Unified Database Management Systems](https://www2.helsinki.fi/en/researchgroups/unified-database-management-systems-udbms/news), University of Helsinki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be83192-8331-4177-ab26-d4a37ad81e97",
   "metadata": {},
   "source": [
    "This is just a specified shortest path finding application applied to the problem presented in the [document](https://github.com/valterUo/Quantum-Computing-based-Optimization-for-Sustainable-Data-Workflows-in-Cloud/blob/main/Quantum_Computing__based_Optimization_for_Sustainable_Data_Workflows_in_Cloud.pdf) that comes along with this implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774c742-8f1d-4edf-af43-af3866b25424",
   "metadata": {},
   "source": [
    "Possible quantum software-harware combinations to solve the problem:\n",
    "\n",
    "1. Amazon Braket: Ocean implementation of this code\n",
    "2. D-wave's Leap Advantage: Ocean implementation of this code\n",
    "3. IBM Quantum systems\n",
    "    1. Simulator in cloud\n",
    "    2. NISQ device in cloud\n",
    "4. Local machine\n",
    "    1. Ocean's imulated annealing\n",
    "    2. Qiskit's local qasm simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ec7e3-bc29-4470-98bb-9e06c57ec2d1",
   "metadata": {},
   "source": [
    "## Part 1: Implementation with Ocean connecting to Amazon Braket and D-wave Leap quantum annealers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8921259b-eca6-477c-a2eb-690f7722c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy\n",
    "#!{sys.executable} -m pip install ocean_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3c7485-15bb-4983-aef2-cbdd4d1aac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dimod\n",
    "from dimod.generators.constraints import combinations\n",
    "from dwave.system import LeapHybridSampler\n",
    "from hybrid.reference import KerberosSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "\n",
    "from braket.aws import AwsDevice\n",
    "from braket.ocean_plugin import BraketSampler, BraketDWaveSampler\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "notebook_path = os.path.abspath(\"main.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4b31cb-e659-47c2-9cba-205a044790c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_linear_safe(variable, value, linear_dict):\n",
    "    if variable in linear_dict.keys():\n",
    "        linear_dict[variable] = linear_dict[variable] + value\n",
    "    else:\n",
    "        linear_dict[variable] = value\n",
    "\n",
    "def append_quadratic_safe(variable, value, quadratic_dict):\n",
    "    if variable in quadratic_dict.keys():\n",
    "        quadratic_dict[variable] = quadratic_dict[variable] + value\n",
    "    else:\n",
    "        quadratic_dict[variable] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce68ea1-d49c-4060-9f94-739a02b61a6e",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc2be6-0f34-42e4-ac0e-4f8a98ef5e83",
   "metadata": {},
   "source": [
    "This demonstration implements three different sized data sets. Comment and uncomment the data sets you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0788258a-13b0-4e9f-baae-9de21302c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration 1\n",
    "\n",
    "cloud_partners_data = \"cloud_partners_small.json\"\n",
    "workload_data = \"workload_small.json\"\n",
    "strength = 1500.0\n",
    "\n",
    "# Demonstration 2\n",
    "\n",
    "#cloud_partners_data = \"cloud_partners_medium.json\"\n",
    "#workload_data = \"workload_medium.json\"\n",
    "#strength = 40.0\n",
    "\n",
    "# Demonstration 3\n",
    "\n",
    "#cloud_partners_data = \"cloud_partners_large.json\"\n",
    "#workload_data = \"workload_large.json\"\n",
    "#strength = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ab1f70-b45b-4362-bc5f-68999bb694b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_partners_file_path = os.path.join(os.path.dirname(notebook_path), \"data/single_round_data/cloud_partners/\" + cloud_partners_data)\n",
    "f = open(cloud_partners_file_path)\n",
    "partners_root = json.load(f)\n",
    "cloud_partners = partners_root[\"cloud_partners\"]\n",
    "\n",
    "workload_file_path = os.path.join(os.path.dirname(notebook_path), \"data/single_round_data/workloads/\" + workload_data)\n",
    "f = open(workload_file_path)\n",
    "workload_root = json.load(f)\n",
    "workload = workload_root[\"workload\"]\n",
    "\n",
    "#print(\"Cloud partners: \", json.dumps(cloud_partners, indent=1))\n",
    "#print(\"Workloads: \", json.dumps(workload, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a910aa5-40f4-4503-b216-03d9be89ae63",
   "metadata": {},
   "source": [
    "## Emission simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5b2c0-6cc3-438a-b0eb-632d3562cd93",
   "metadata": {},
   "source": [
    "This section implements an emission simulator which simulates emission changes in data center operations. Note that it is relatively hard to get accurate data from individual data centers. This simulator is just for demonstration and it does not have an actual scientific background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab183fa1-db52-45d7-8603-fdcbd24baf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_simulator(variable1, variable2, cloud_partners, workload):\n",
    "    simulated_carbon_footprint = 1\n",
    "    emission_factor = 1\n",
    "    workload_type_in_process = None\n",
    "    \n",
    "    source_data_center_id = variable1[1]\n",
    "    work_in_process = variable2[0]\n",
    "    target_data_center_id = variable2[1]\n",
    "    \n",
    "    for work in workload:\n",
    "        if work[\"work_id\"] == int(work_in_process):\n",
    "            emission_factor = work[\"emission_factor\"]\n",
    "            workload_type_in_process = work[\"work_type\"]\n",
    "    \n",
    "    for partner in cloud_partners:\n",
    "        for center in partner[\"data_centers\"]:\n",
    "            # Find correct target center\n",
    "            if target_data_center_id == center[\"center_id\"]:\n",
    "                for workload_type in center[\"workload_dependent_emissions\"]:\n",
    "                    # Find correct workload type i.e. Big Data, IoT, ML, etc.\n",
    "                    if workload_type_in_process == workload_type[\"workload_type\"]:\n",
    "                        center_emission_factor = workload_type[\"center_emission_factor\"]\n",
    "                        #print(center_emission_factor)\n",
    "                        simulated_carbon_footprint = emission_factor*center_emission_factor\n",
    "            \n",
    "    return simulated_carbon_footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa518671-f5cc-43b3-8cbd-363d8a30f06e",
   "metadata": {},
   "source": [
    "## Creating variables for the binary quadratic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74690d-32f8-4e23-bea3-4710042fcf4b",
   "metadata": {},
   "source": [
    "In the demo paper we defined variables to be $ x_{i,j} = (w_i, d_j) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd702685-2279-4e62-9ce2-3af9de8b92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "variables = dict()\n",
    "workload_order = []\n",
    "\n",
    "for work in workload:\n",
    "    variables[str(work[\"work_id\"])] = list()\n",
    "    workload_order.append(str(work[\"work_id\"]))\n",
    "    for partner in cloud_partners:\n",
    "        for center in partner[\"data_centers\"]:\n",
    "            # The each key in the variables dictionary corresponds to a level in a tree i.e. a time step in the workflow\n",
    "            variables[str(work[\"work_id\"])].append((str(work[\"work_id\"]), center[\"center_id\"]))\n",
    "            \n",
    "#print(json.dumps(variables, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6199eb-3f5e-4e91-a882-ff80136fcbcb",
   "metadata": {},
   "source": [
    "## Constructing constraints "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0502bff-f291-45b0-a710-a0c5b153fef7",
   "metadata": {},
   "source": [
    "### Constraint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7801573-9127-4f54-ad3b-28aca620ac5a",
   "metadata": {},
   "source": [
    "This constraint implements the requirement that for every work $ w_i $ we have exactly one variable $ x_{i,j} = (w_i, d_j) = 1$. In other words, this means that every work is executed exactly on a single data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7bc9f9-b944-4fbe-8069-2ccc3680b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bqm_constraint1(bqm, variables, strength):\n",
    "    for work_id in variables:\n",
    "        one_work_bqm = combinations(variables[work_id], 1, strength=strength)\n",
    "        bqm.update(one_work_bqm)\n",
    "    return bqm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbdb8a-44b2-4c36-aa22-b44f490355b4",
   "metadata": {},
   "source": [
    "### Constraint 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c4051-e147-4517-8176-0bc3efaab475",
   "metadata": {},
   "source": [
    "This constraint implements the requirement that for every pair of variables $x_{i,j} = (w_i, d_j)$ and $x_{i+1,k} = (w_{i+1}, d_k)$ we associate the estimated emission coefficient $e(x_{i,j}, x_{i+1,k})$. This coefficient is calculated in emission_simulator function. Note that we need to calculate this only for those pairs, where the works $w_i$ and $w_{i+1}$ are consecutive works in the workload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1731c43-df52-4056-aa1e-1cc817aeacce",
   "metadata": {},
   "source": [
    "To evaluate the algorithm we store the tree in a networkx graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405cb56c-74e8-4769-ad68-181fef27f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bqm_constraint2(bqm, variables, workload_order):\n",
    "    vartype = dimod.BINARY\n",
    "    A = 1\n",
    "    linear = dict()\n",
    "    quadratic = dict()\n",
    "    offset = 0.0\n",
    "    tree = nx.Graph()\n",
    "\n",
    "    for work_id_current in range(len(workload_order) - 1):\n",
    "        work_id_next = work_id_current + 1\n",
    "        key_current = workload_order[work_id_current]\n",
    "        key_next = workload_order[work_id_next]\n",
    "\n",
    "        for work1 in variables[key_current]:\n",
    "            for work2 in variables[key_next]:\n",
    "                \n",
    "                coeff = emission_simulator(work1, work2, cloud_partners, workload)\n",
    "                \n",
    "                append_quadratic_safe((work1, work2), coeff, quadratic)\n",
    "                tree.add_edge(work1, work2, weight=coeff)\n",
    "\n",
    "                #print(\"Works\", work1, work2)\n",
    "                #print(\"Coefficient\", coeff)\n",
    "\n",
    "    bqm_c2 = dimod.BinaryQuadraticModel(linear, quadratic, offset, vartype)\n",
    "    bqm_c2.scale(A)\n",
    "    bqm.update(bqm_c2)\n",
    "    return bqm, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da83177-51ac-4765-a36c-ab4a85a686e4",
   "metadata": {},
   "source": [
    "## Demonstrating algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8816e245-2865-448d-8c3d-d6f3a53fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_optimal(solution, tree, optimal_weight):\n",
    "    current_total = 0\n",
    "    try:\n",
    "        for i in range(len(solution) - 1):\n",
    "            edge_weight = tree.get_edge_data(solution[i], solution[i+1])\n",
    "            current_total += edge_weight[\"weight\"]\n",
    "    except:\n",
    "      print(\"The quantum result contains edges which are not in the tree.\")\n",
    "    return np.abs(optimal_weight - current_total)/optimal_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d00f96-829a-42d0-b462-8af9a1dc35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(sample, tree, optimal_weight = -1):\n",
    "    positive_solution = []\n",
    "    for varname, value in sample.items():\n",
    "        if value == 1:\n",
    "            positive_solution.append(varname)\n",
    "            print(varname, value)\n",
    "    if optimal_weight != -1:\n",
    "        print(\"Difference from the optimal \", compare_to_optimal(positive_solution, tree, optimal_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a08ab-3221-41ce-a365-23227f7e3fd6",
   "metadata": {},
   "source": [
    "### Wrapping up various methods to solve the QUBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae0586e-e308-4b09-a492-7fde27d5ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_bqm_in_leap(bqm, sampler = \"Kerberos\"):\n",
    "    bqm.normalize()\n",
    "    if sampler == \"Kerberos\":\n",
    "        kerberos_sampler = KerberosSampler().sample(bqm, max_iter=10, convergence=3, qpu_params={'label': 'Data workflow optimization'})\n",
    "        sample = kerberos_sampler.first.sample\n",
    "        # print timing info for the previous D-Wave job\n",
    "        #print(kerberos_sampler.info['additionalMetadata']['dwaveMetadata']['timing'])\n",
    "    elif sampler == \"LeapHybrid\":\n",
    "        sampler = LeapHybridSampler()\n",
    "        sampleset = sampler.sample(bqm)\n",
    "        sample = sampleset.first.sample\n",
    "        # print timing info for the previous D-Wave job\n",
    "        print(sampleset.info['additionalMetadata']['dwaveMetadata']['timing'])\n",
    "    return sample\n",
    "    \n",
    "    #print(sampleset)\n",
    "    #print(best_solution)\n",
    "    #sample = best_solution\n",
    "    #energy = sampleset.first.energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce703015-9869-4954-aa9c-4f334c7db668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_bqm_in_amazon_braket(bqm, system = \"Advantage\"):\n",
    "    device = None\n",
    "    num_reads = 1000\n",
    "    if system == \"Advantage\":\n",
    "        device = \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\"\n",
    "    elif system == \"2000Q\":\n",
    "        device = \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\"\n",
    "    sampler = BraketDWaveSampler(device_arn = device)\n",
    "    sampler = EmbeddingComposite(sampler)\n",
    "    sampleset = sampler.sample(bqm, num_reads=num_reads)\n",
    "    sample = sampleset.first.sample\n",
    "    \n",
    "    # print timing info for the previous D-Wave job\n",
    "    print(sampleset.info['additionalMetadata']['dwaveMetadata']['timing'])\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2053039f-9832-40c4-b107-f51a463e2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_simulated_annealing(bqm):\n",
    "    sampler = dimod.SimulatedAnnealingSampler()\n",
    "    sampleset = sampler.sample(bqm, num_reads=100)\n",
    "    sample = sampleset.first.sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b510e515-c45e-49f7-95bd-169dbe86f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_exactly(bqm):\n",
    "    sampler = dimod.ExactSolver()\n",
    "    sampleset = sampler.sample(bqm)\n",
    "    sample = sampleset.first.sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549a4ccf-b4b9-40ca-8cf3-6f92c54a2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_networkx(tree, variables, start_work):\n",
    "    possible_solutions = []\n",
    "    best_solution = None\n",
    "    min_weight = float('Inf')\n",
    "    for source_var in variables[start_work]:\n",
    "        for target_var in variables[str(len(variables) - 1)]:\n",
    "            possible_solutions.append(nx.dijkstra_path(tree, source=source_var, target=target_var))\n",
    "    for sol in possible_solutions:\n",
    "        current_total = 0\n",
    "        for i in range(len(sol) - 1):\n",
    "            edge_weight = tree.get_edge_data(sol[i], sol[i+1])\n",
    "            current_total += edge_weight[\"weight\"]\n",
    "        #print(\"Shortest path \", sol)\n",
    "        #print(\"Current total \", current_total)\n",
    "        if min_weight > current_total:\n",
    "            min_weight = current_total\n",
    "            best_solution = sol\n",
    "    return best_solution, min_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d6270-d44a-4051-a11d-7d8955f19442",
   "metadata": {},
   "source": [
    "## Run single time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93196b6-68bf-4370-9815-59e8acc55e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vartype = dimod.BINARY\n",
    "bqm = dimod.BinaryQuadraticModel({}, {}, 0.0, vartype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f2b996-383a-4c62-9a95-fdd7dbb299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit construct_bqm_constraint1(bqm, variables, strength)\n",
    "#%timeit construct_bqm_constraint2(bqm, variables, workload_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf6324b-d690-42b2-83f6-9e990737e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqm = construct_bqm_constraint1(bqm, variables, strength)\n",
    "bqm, tree = construct_bqm_constraint2(bqm, variables, workload_order)\n",
    "# print(bqm)\n",
    "\n",
    "#print(\"The problem is to find the minimum path from some of the nodes ('0', x) to some of the nodes ('5', y). The weight of the edges are defined by carbon footprint associated to the computation.\")\n",
    "#nx.draw(tree, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a390173-f0d1-42be-9924-490ea7c3ac6d",
   "metadata": {},
   "source": [
    "#### Optimal and correct solution for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200501aa-05e4-4ae3-a3fc-31ba78f030c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit solve_with_networkx(tree, variables, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f4d8776-a48e-4893-94f2-8791856c3d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', '00'), ('1', '00'), ('2', '10')] 108\n"
     ]
    }
   ],
   "source": [
    "best_solution, optimal_weight = solve_with_networkx(tree, variables, '0')\n",
    "print(best_solution, optimal_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21cf8d-c862-40f6-a16a-c3f56358347f",
   "metadata": {},
   "source": [
    "The following results we obtain with annealing. Ideally we would be close to the results we obtain from the function solve_with_networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a5e589-0518-46d1-95d1-68d515e98db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution with D-wave Leap\n",
      "('0', '00') 1\n",
      "('1', '00') 1\n",
      "('2', '10') 1\n",
      "Difference from the optimal  0.0\n"
     ]
    }
   ],
   "source": [
    "#print(\"Solution with Amazon Braket\")\n",
    "#solution = solve_bqm_in_amazon_braket(bqm)\n",
    "#print_solution(solution, tree, optimal_weight)\n",
    "\n",
    "print(\"Solution with D-wave Leap\")\n",
    "solution = solve_bqm_in_leap(bqm)\n",
    "print_solution(solution, tree, optimal_weight)\n",
    "\n",
    "#print(\"Solution with simulated annealing\")\n",
    "#solve_with_simulated_annealing(bqm)\n",
    "\n",
    "#print(\"Exact solution (takes time)\")\n",
    "#solve_exactly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e5533-9632-4d03-bb95-f8dc8ad12988",
   "metadata": {},
   "source": [
    "## Part 2: Transfering problem to Qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fe1b7-cb71-423b-9ed0-9d7b30e913d4",
   "metadata": {},
   "source": [
    "In this part of the code I rely on the [Qiskit Tutorials](https://qiskit.org/documentation/optimization/tutorials/index.html). I want to learn to understand the connection between Ocean implementation and Qiskit. The formulation in Qiskit enables solving the problem using IBM Quantum systems. Although Amazon Braket does not implement the following kind of approach, it might be possible to translate the Qiskit into the equivalent Pennylane code and run it in Braket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab11ca8-4dc4-442a-8474-7d256b0caedf",
   "metadata": {},
   "source": [
    "### Importing Qiskit and IBM Quantum Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a9e31b-2c3d-405b-9d4f-7ff6e05f41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "from qiskit import BasicAer\n",
    "from qiskit.utils import algorithm_globals, QuantumInstance\n",
    "from qiskit.algorithms import QAOA, NumPyMinimumEigensolver\n",
    "from qiskit_optimization.algorithms import (\n",
    "    MinimumEigenOptimizer,\n",
    "    RecursiveMinimumEigenOptimizer,\n",
    "    SolutionSample,\n",
    "    OptimizationResultStatus,\n",
    ")\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a1260-5b4a-4675-a356-dbc4cec1467c",
   "metadata": {},
   "source": [
    "We start by importing a smaller data sets. After testing with the bigger data sets, we noted that the processing takes very long. So for the demonstration it makes sense to run the code only with these smaller data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39f5fe6-8f51-493e-88a7-3c87312d39c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\valte\\\\Desktop\\\\Quantum-Computing-based-Optimization-for-Sustainable-Data-Workflows-in-Cloud\\\\VLDB2022_demos\\\\data/cloud_partners_small.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m cloud_partners_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(notebook_path), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/cloud_partners_small.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcloud_partners_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m partners_root \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m cloud_partners_small \u001b[38;5;241m=\u001b[39m partners_root[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcloud_partners\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\valte\\\\Desktop\\\\Quantum-Computing-based-Optimization-for-Sustainable-Data-Workflows-in-Cloud\\\\VLDB2022_demos\\\\data/cloud_partners_small.json'"
     ]
    }
   ],
   "source": [
    "cloud_partners_file_path = os.path.join(os.path.dirname(notebook_path), \"data/cloud_partners_small.json\")\n",
    "f = open(cloud_partners_file_path)\n",
    "partners_root = json.load(f)\n",
    "cloud_partners_small = partners_root[\"cloud_partners\"]\n",
    "\n",
    "workload_name = \"workload2.json\"\n",
    "workload_file_path = os.path.join(os.path.dirname(notebook_path), \"data/workloads/\" + workload_name)\n",
    "f = open(workload_file_path)\n",
    "workload_root = json.load(f)\n",
    "workload_small = workload_root[\"workload\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f20698-c184-4678-ba3e-e1f4364c6066",
   "metadata": {},
   "source": [
    "### Transforming QUBO in Ocean to QUBO in Qiskit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435286f1-67e2-4530-92f4-d41e64b4898c",
   "metadata": {},
   "source": [
    "Constructing BQM in Ocean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774256a-5072-4416-bbb9-671285331433",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqm = dimod.BinaryQuadraticModel({}, {}, 0.0, dimod.BINARY)\n",
    "variables, work_order = construct_variables(workload_small, cloud_partners_small, 0)\n",
    "bqm = construct_bqm_constraint1(bqm, variables)\n",
    "bqm, tree = construct_bqm_constraint2(bqm, variables, work_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c1625-7b33-4a1a-9ee0-a107121e37e2",
   "metadata": {},
   "source": [
    "Solving the problem optimally using the classical algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229acee1-7fba-42ea-842f-7957e1ae6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution, optimal_weight = solve_with_networkx(tree, variables, '0')\n",
    "print(\"Best solution with networkx: \", optimal_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7562e4-f19e-454e-a905-7b3038d7b2ea",
   "metadata": {},
   "source": [
    "Function for evaluating Qiskit result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a7d01-cdcc-43bc-ac1f-987f2625d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qiskit_solution(result, tree, optimal):\n",
    "    #print(result.variables_dict)\n",
    "    path = []\n",
    "    for key in result.variables_dict:\n",
    "        if result.variables_dict[key] == 1.0:\n",
    "            path.append(eval(key))\n",
    "    print(\"Difference (in [0,1]) between the optimal solution and the solution found with Qiskit:\")\n",
    "    print(compare_to_optimal(path, tree, optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac0cfd-b742-4701-a906-0c193e2d2717",
   "metadata": {},
   "source": [
    "Transforming the QUBO in Qiskit. We use QAOA module in order to understand the details of the process better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb26c7-1237-4128-b8cb-a598d0f9523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubo = QuadraticProgram()\n",
    "qubo_variables = []\n",
    "for var in bqm.variables:\n",
    "    qubo.binary_var(str(var))\n",
    "    qubo_variables.append(str(var))\n",
    "\n",
    "constant = bqm.offset\n",
    "linear = []\n",
    "quadratic = {}\n",
    "\n",
    "for var in bqm.variables:\n",
    "    linear.append(bqm.linear[var])\n",
    "    \n",
    "for key in bqm.quadratic:\n",
    "    quadratic[(str(key[0]), str(key[1]))] = bqm.quadratic[key]\n",
    "\n",
    "#print(\"Variables: \", qubo_variables)\n",
    "#print(\"Offset \", constant)\n",
    "#print(\"Linear \", linear)\n",
    "#print(\"Quadratic \", quadratic)\n",
    "\n",
    "qubo.minimize(constant = constant, linear=linear, quadratic=quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb75d59-9a37-47f1-9a38-1440fb4fca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = BasicAer.get_backend(\"qasm_simulator\")\n",
    "#backend = provider.get_backend('ibmq_qasm_simulator')\n",
    "\n",
    "algorithm_globals.random_seed = 10598\n",
    "quantum_instance = QuantumInstance(\n",
    "    backend = backend,\n",
    "    seed_simulator=algorithm_globals.random_seed,\n",
    "    seed_transpiler=algorithm_globals.random_seed,\n",
    ")\n",
    "qaoa_mes = QAOA(quantum_instance=quantum_instance)\n",
    "exact_mes = NumPyMinimumEigensolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccb615-ba82-4f5c-b23a-f596ee6e3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qaoa = MinimumEigenOptimizer(qaoa_mes)  # using QAOA\n",
    "#exact = MinimumEigenOptimizer(exact_mes)  # using the exact classical numpy minimum eigen solver\n",
    "\n",
    "#qaoa_result = qaoa.solve(qubo)\n",
    "#print(qaoa_result)\n",
    "#print()\n",
    "#evaluate_qiskit_solution(qaoa_result, tree, optimal_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b85722-0519-4283-a952-e5e410592fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rqaoa = RecursiveMinimumEigenOptimizer(qaoa, min_num_vars=1, min_num_vars_optimizer=exact)\n",
    "#rqaoa_result = rqaoa.solve(qubo)\n",
    "#print(rqaoa_result)\n",
    "print()\n",
    "#evaluate_qiskit_solution(rqaoa_result, tree, optimal_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
